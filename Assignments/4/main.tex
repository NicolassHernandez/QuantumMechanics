\documentclass[letterpaper,11pt,twoside]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[table,xcdraw,dvipsnames]{xcolor}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{enumitem}

\usepackage{tikz}
\usepackage[siunitx, RPvoltages]{circuitikz}
\usetikzlibrary{3d}
\usepackage{comment}
\usepackage{caption,subcaption}
\usepackage{pgfplots}
\pgfplotsset{compat=newest} % or a newer version if available
\usepgfplotslibrary{groupplots}
\usetikzlibrary{pgfplots.groupplots}
\usetikzlibrary{shapes.geometric, arrows}
\tikzstyle{arrow} = [->,>=stealth,shorten >=2pt]
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\br}{\bm{r}}
\newcommand{\bR}{\bm{R}}
\newcommand{\bp}{\bm{p}}
\newcommand{\bP}{\bm{P}}
\newcommand{\braket}[1]{\langle#1\rangle}
\newcommand{\F}{\mathscr{F}}
\newcommand{\E}{\mathscr{E}}
\usepackage{dsfont}
\usepackage{cancel}
\usepackage{bm}
\usepackage{fancyhdr}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[margin=0.8in,top=1in,bottom=1in]{geometry}
%%%%%
\begin{filecontents*}{refs.bib}
@book{bornwolf,
  author    = {Born, M. and Wolf, E.},
  title     = {Principles of Optics},
  publisher = {Pergamon Press},
  edition   = {7},
  year      = {1999}
}
@book{hecht,
  author    = {Hecht, E.},
  title     = {Optics},
  publisher = {Addison-Wesley},
  edition   = {5},
  year      = {2016}
}
\end{filecontents*}
%
\newcommand{\institution}{University of Arizona}
\newcommand{\autor}{Nicolás Hernández Alegría}
\newcommand{\course}{OPTI 570 Quantum Mechanics}
\newcommand{\assignment}{Assignment 4}
%
\title{\textbf{\assignment}\\\course\\{\Large\institution}}
\author{\autor}
\date{\today\\Total time: $\infty$ hours}
%
\renewcommand{\sectionmark}[1]{\markright{#1}}
\fancypagestyle{mainstyle}{
    \fancyhf{} % Clear all header and footer fields
    \fancyfoot[C]{\thepage}
    \fancyhead[LE,RO]{\course} % Section name on odd pages
    \fancyhead[LO,RE]{\assignment}
    % Optional: Thin rules
    \renewcommand{\headrulewidth}{0pt} % Header rule
    \renewcommand{\footrulewidth}{0pt} % No footer rule
}
%
\begin{document}

\pagestyle{mainstyle}
\maketitle
%%

\section*{Problem I}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*)]
  \item The sixth postulates of Quantum mechanics states the time evolution of the state $\ket{\psi}$: 
  \begin{align}
    i\hbar\frac{d}{dt}\ket{\psi(t)}=H(t)\ket{\psi(t)}.
    \label{eq:schrodinger}
  \end{align}
  If we multiplty equation \eqref{eq:schrodinger} by $\bra{\phi(t)}$ and use the product rule of differentiation we get 
  \begin{align*}
    \frac{d}{dt}\braket{\psi(t)|\phi(t)}&=\left[\frac{d}{dt}\bra{\psi(t)}\right]\ket{\phi(t)}+\bra{\psi(t)}\left[\frac{d}{dt}\ket{\phi(t)}\right].
  \end{align*}
  On the one hand, from Schrodinger equation we have 
  \begin{align*}
    \frac{d}{dt}\ket{\phi(t)}=\frac{1}{i\hbar}H(t)\ket{\phi(t)}.
  \end{align*}
  On the other hand, if we compute the adjoint of the Schrodinger equation for $\ket{\psi(t)}$:
  \begin{align*}
    \frac{d}{dt}\bra{\psi(t)}=-\frac{1}{i\hbar}\bra{\psi(t)}H(t).\qquad(H^\dagger(t)=H(t))
  \end{align*}
  Replacing both results into the product rule yields:
  \begin{align}
    \frac{d}{dt}\braket{\psi(t)|\phi(t)}&=\left[-\frac{1}{i\hbar}\bra{\psi(t)}H(t)\right]\ket{\phi(t)}+\bra{\psi(t)}\left[\frac{1}{i\hbar}H(t)\ket{\phi(t)}\right]\notag\\
    &=-\frac{1}{i\hbar}\braket{\psi(t)|H(t)|\phi(t)}+\frac{1}{i\hbar}\braket{\psi(t)|H(t)|\phi(t)}\label{eq:interproblem1}\\
    \frac{d}{dt}\braket{\psi(t)|\phi(t)}&=0.\notag
  \end{align}
  %%
  The evolution of a state $\ket{\psi(t_0)}$ to $\ket{\psi(t)}$ follows a linear fashion. Therefore, the transformation can be represented by a linear evolution operator 
  $U(t,t_0)$ so that 
  \begin{align}
    \ket{\psi(t)}=U(t,t_0)\ket{\psi(t_0)}.
  \end{align}
  The time derivative is zero means that the argument must be a constant:
  \begin{align*}
    \frac{d}{dt}\braket{\varphi(t)|\phi(t)}=0\Longrightarrow \braket{\varphi(t)|\phi(t)}=\text{cte}=\braket{\varphi(t_0)|\phi(t_0)}.
  \end{align*}
  We put the definition of the evolution operator
  \begin{align*}
    \braket{\varphi(t_0)U^\dagger(t,t_0)U(t,t_0)|\phi(t_0)}=\braket{\varphi(t_0)|\phi(t_0)}
  \end{align*}
  By comparison, we have that 
  \begin{align*}
    U^\dagger(t,t_0)U(t,t_0)=\mathds{1},
  \end{align*}
  which is the definition of an unitary operator.
  %%
  \item If $\ket{\psi(t_0)}=\ket{\phi_n^i}$, then the state is fully characterized by a single eigenvector of the Hamiltonian. This corresponds to its expansion
  \begin{align*}
    \ket{\psi(t)}=c_n(t)\ket{\phi_n^i},\quad\text{with}\quad c_n(t)=\braket{\phi_n^i|\psi(t)}=1.
  \end{align*} 
    We use the coeffficient in the Schrodinger equation:
    \begin{align*}
      i\hbar\frac{d}{dt}\braket{\phi_n^i|\psi(t)}=\braket{\phi_n^i|H|\psi(t)}=E_n\braket{\phi_n^i|\psi(t)}.
    \end{align*}
    The first and last equation, construct a first-order differential equation in the coefficient $c_n(t)$:
    \begin{align*}
      i\hbar\frac{d}{dt}c_n(t)=E_nc_n(t)\longrightarrow c_n(t)=c_n(t_0)e^{-E_n(t-t_0)/\hbar},
    \end{align*}
    where $c_n(t_0)$ is the value for $\psi(t_0)$, in this case, $\psi(t_0)=\ket{\psi_n^i}$ and $c_n(t_0)=1$. Therefore,
    \begin{align*}
      \ket{\psi(t)}=1e^{-iE_n(t-t_0)/\hbar}\ket{\psi(t_0)}.
    \end{align*}
  \item In the general case, where the state vector has more than one coefficient of projection, we can do the same with the inclusion of the summation for each coefficient, including 
  also the degree of degeneracy. We can think of the previous result as just one of the several terms, but all share the same structure.
  We give a small derivation,
  \begin{align*}
    \sum_{n,i}i\hbar\frac{d}{dt}c^i_n(t)=\sum_{n,i}E_nc^i_n(t)\longrightarrow\sum_{n,i}c_{n,i}(t)=\sum_{n,i}c_{n,i}(t_0)e^{-E_n(t-t_0)/\hbar},
  \end{align*} 
  The equations above are for each eigenvector, which then construct the state vector:
  \begin{align*}
    \ket{\psi(t)}=\sum_{n,i}c_n^i(t_0)e^{-iE_n(t-t_0)/\hbar}\ket{\phi_n^i}.
  \end{align*} 
  To be a stationary state, there only have to be a global phase common to all the eigenvectors. However, if the state vector is represented by several eigenvectors,
  each one will have its own phase, that represent the relative phase factor. How behaves this phase factor depends on the argument of the esponential term:
  $-iE_n(t-t_0)/\hbar$. The only variable we can study is $E_n$ that corresponds to the eigenvalue. In order to remain the phase equal for all the eigenvectors, 
  we need that $E_n=E_{n+1}=\cdots=E$, that is, we should live in a single eigensubspace of the Hamiltonian, which may have several eigenvectors but all share the same eigenvalue and therefore 
  the same phase factor. 
\end{enumerate}
%%
\section*{Problem II}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*.]
  \item We need to normalized the wavefunction in the range $x\in(-\infty,\infty)$ so that its norm is unitary.
  \begin{align*}
    \int_{-\infty}^\infty dx\;|\psi(x)|^2&=\int_{-\infty}^\infty dx\;\left|N\frac{e^{ip_0x/\hbar}}{\sqrt{x^2+a^2}}\right|^2=N^2\int_{-\infty}^\infty dx\;\frac{1}{x^2+a^2}=N^2\frac{\pi}{a}=1\longrightarrow N=\sqrt{\frac{a}{\pi}}.
  \end{align*}
  The integral was computed with the change of variable $x=a\tan\theta$. The wave function is then
  \begin{align*}
    \psi(x)=\sqrt{\frac{a}{\pi}}\frac{e^{ip_0x/\hbar}}{\sqrt{x^2+a^2}}.
  \end{align*}
  \item To find the probability in the range given, we integrate $|\psi(x)|^2$ in the interval. We also notice that the integrand will be even, so we only integrate one part and multiply it by two:
  \begin{align*}
    \sqrt{\frac{a}{\pi}}\int_{-a/\sqrt{3}}^{a/\sqrt{3}}\frac{1}{x^2+a^2}=2\sqrt{\frac{a}{\pi}}\int_{0}^{a/\sqrt{3}}\frac{1}{x^2+a^2}=\frac{\sqrt{\pi}}{3\sqrt{a}}.
  \end{align*}
  \item To get the mean value of the momentum, we will compute the following:
  \begin{align*}
    \braket{P}_\psi=\braket{\psi|P|\psi}=\braket{\psi|\mathds{1}P|\psi}=\int dx\;\braket{\psi|x}\braket{x|P|\psi}=\int dx\;\psi^*(x)[-i\hbar\partial_x\psi(x)].
  \end{align*}
  The time derivative is:
  \begin{align*}
    \partial_x\psi(x)=\sqrt{\frac{a}{\pi}}\left[\frac{ip_o}{\hbar}(x^2+a^2)^{-1/2}-x(x^2+a^2)^{-3/2}\right]e^{ip_0x/\hbar}.
  \end{align*}
  The multiplication $\psi^*(x)\cdot\partial_x\psi(x)$ is:
  \begin{align*}
    \psi^*(x)\cdot\partial_x\psi(x)&=\sqrt{\frac{a}{\pi}}(x^2+a^2)^{-1/2}e^{-ip_0x/\hbar}\cdot\sqrt{\frac{a}{\pi}}\left[\frac{ip_o}{\hbar}(x^2+a^2)^{-1/2}-x(x^2+a^2)^{-3/2}\right]e^{ip_0x/\hbar}\\
    &=\frac{a}{\pi}(x^2+a^2)^{-1/2}\left[\frac{ip_o}{\hbar}(x^2+a^2)^{-1/2}-x(x^2+a^2)^{-3/2}\right]\\
    \psi^*(x)\cdot\partial_x\psi(x)&=\frac{a}{\pi}\left[\frac{ip_o}{\hbar}(x^2+a^2)^{-1/2}-x(x^2+a^2)^{-2}\right].
  \end{align*}
  We proceed to integrate it:
  \begin{align*}
    \braket{P}_\psi&=\frac{-i\hbar a}{\pi}\left[\frac{ip_o}{\hbar}\int_{-\infty}^\infty dx\;(x^2+a^2)^{-1/2}-\int_{-\infty}^\infty dx\;x(x^2+a^2)^{-2}\right]\\
    &=\frac{-i\hbar a}{\pi}\left[\frac{ip_o}{\hbar}\frac{\pi}{|a|}-0\right]\\
    &=\frac{-i\hbar a}{\pi}\frac{ip_o}{\hbar}\frac{\pi}{|a|}\\
    \braket{P}_\psi&=p_o.
  \end{align*}
\end{enumerate}
%%
\section*{Problem III}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*.]
  \item In this case, the wave function is expanded in a discrete set $\{\psi_n\}$ of length four. Each of these eigenvectors has a $E_n$
  asociated. We are asked of the probability of getting an energy less than $E_{\approx2.4}$, which is the same than asking for a probability 
  less or equal than $E_2$.
  \begin{align*}
    P(H\leq E_2)=\frac{1}{\braket{\psi|\psi}}\sum_{n=1}^2\braket{\psi|P_n|\psi}=\frac{1}{\braket{\psi|\psi}}\left[\braket{\psi|P_1|\psi}+\braket{\psi|P_2|\psi}\right]=\frac{|a_1|^2+|a_2|^2}{|a_1|^2+|a_2|^2+|a_3|^2+|a_4|^2}.
  \end{align*}
  \item On the one hand, the mean value of the enegy is:
  \begin{align*}
    \braket{H}_\psi=\frac{\braket{\psi|H|\psi}}{\braket{\psi|\psi}}=\frac{\sum_n\braket{\psi|\varphi_n}\braket{\varphi_n|H|\psi}}{\braket{\psi|\psi}}=\frac{\sum_n|a_n|^2E_n}{\braket{\psi|\psi}}=\frac{|a_1|^2E_1+|a_2|^2E_2+|a_3|^2E_3+|a_4|^4E_4}{|a_1|^2+|a_2|^2+|a_3|^2+|a_4|^2}.
  \end{align*}
  On the other hand, the RMS deviation of the energy is:
  \begin{align*}
    \Delta H=\sqrt{\braket{H^2}-\braket{H}^2}.
  \end{align*}
  The term $\braket{E^2}_\psi$ must be recalculated following the previous procedure:
  \begin{align*}
    \braket{H^2}_\psi=\frac{\braket{\psi|H^2|\psi}}{\braket{\psi|\psi}}=\frac{\sum_n|a_n|^2E^2_n}{\braket{\psi|\psi}}=\frac{|a_1|^2E^2_1+|a_2|^2E^2_2+|a_3|^2E^2_3+|a_4|^4E^2_4}{|a_1|^2+|a_2|^2+|a_3|^2+|a_4|^2}.
  \end{align*}
  Finally, the RMS deviation is:
  \begin{align*}
    \Delta H=\sqrt{\frac{\sum_n|a_n|^2E^2_n}{\braket{\psi|\psi}}-\left(\frac{\sum_n|a_n|^2E_n}{\braket{\psi|\psi}}\right)^2}.
  \end{align*}
  \item The Hamiltonian of this system does not depend on time so that the system in conservative. We already know the expansion of the state vector at $t=0$. Therefore, we only need to add the temporal phase
  factor to each of them to construct the state vector at time $t$:
  \begin{align*}
    \ket{\psi(t)}=\sum_{n=1}^4a_ne^{-iE_n(t-t_0)/\hbar}\ket{\varphi_n}.
  \end{align*}
  Because the system is projected in more than one eigenvector of the Hamiltonian, it is not a stationary state. This implies that the the state vector 
  will be different over time due to the relative phase factors, and therefore we expect $\braket{E}$ and $\Delta E$ to change.
  \item When the measurement is performed, the result corresponds to the eigenvalue $E_4$ ($n=4$). This means that the eigenvector obtained in the state of the system
  is $\ket{\varphi_4}$, with the corresponding normalization factor:
  \begin{align*}
    \ket{\psi(t)}\stackrel{(E_4)}{\Longrightarrow}\frac{P_4\ket{\varphi}}{\sqrt{\braket{\psi|P_4|\psi}}}=\frac{a_4}{|a_4|}e^{-iE_4(t-t_0)/\hbar}\ket{\varphi_4}.
  \end{align*}
  Now, we have the state $\ket{\varphi_4}$ just after the measurement. However, because the Hamiltonian is time-independent, it will only evolve a global phase factor that will 
  not affect the physical meaning of the state. In consequence, after the measurement we will always get $\ket{\varphi_4}$.
\end{enumerate}
%%
\section*{Problem IV}
We have the followings eigenpairs for each observator:
\begin{align*}
  H:\qquad&\{(\hbar\omega_0,\ket{u_1}),(2\hbar\omega_0,\ket{u_2}),(2\hbar\omega_0,\ket{u_3})\}.\\
  A:\qquad&\{(a,\ket{u_1}),(a,\ket{+}=\frac{\ket{u_2}+\ket{u_3}}{\sqrt{2}}),(-a,\ket{-}=\frac{\ket{u_2}-\ket{u_3}}{\sqrt{2}})\}.\\
  B:\qquad&\{(b,\ket{+}=\frac{\ket{u_1}+\ket{u_2}}{\sqrt{2}}),(-b,\ket{-}=\frac{\ket{u_1}-\ket{u_2}}{\sqrt{2}}),(b,\ket{u_3})\}.
\end{align*}
We give a small derivation of how the eigenvector of $A$ were obtained. The first case is trivial, but for the second row we have:
\begin{align*}
  A\ket{u_2}=a\ket{u_3}.
\end{align*}
We can see that it doesnt map onto $\ket{u_2}$, but on other vector. We then think of the eigenvector as a combination of them:
\begin{align*}
  \ket{v}=\alpha\ket{u_2}+\beta\ket{u_3}.
\end{align*}
Then,
\begin{align*}
  A\ket{v}=\lambda\ket{v}\longrightarrow a(\beta\ket{u_2}+\alpha\ket{u_3})=\lambda(\alpha\ket{u_2}+\beta\ket{u_3}).
\end{align*}
Equating the vectors results in the following relations:
\begin{align*}
  a\beta=\lambda\alpha\land a\alpha=\lambda\beta\Longrightarrow\lambda^2=\alpha^2.
\end{align*}
For $\lambda=+a$, $\beta=\alpha$ and $\ket{v_+}\propto\ket{u_2}+\ket{u_3}$. For $\lambda=-a$, $\beta=-\alpha$ and $\ket{v_-}\propto\ket{u_2}-\ket{u_3}$. After normalize each 
results we have the eigenket we have listed.
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*.]
  \item The results can only be eigenvalues of the Hamiltonian by the third postulate. Each one has a given probability, therefore:
  \begin{align*}
    \hbar\omega_0,&\quad\text{with}\quad P(\hbar\omega_0)=\braket{\psi|P_{\hbar\omega_0}|\psi}=|\braket{u_1|\psi}|^2=\frac{1}{2}\\
    2\hbar\omega_0,&\quad\text{with}\quad P(2\hbar\omega_0)=\braket{\psi|P_{2\hbar\omega_0}|\psi}=|\braket{u_2|\psi}|^2+|\braket{u_3|\psi}|^2=\frac{1}{4}+\frac{1}{4}=\frac{1}{2}.
  \end{align*}
  In each case the projector was:
  \begin{align*}
    P_{\hbar\omega_0}=\ket{u_1}\bra{u_1}=\begin{bmatrix}
    1&0&0\\0&0&0\\0&0&0
    \end{bmatrix},\quad\text{and}\quad P_{2\hbar\omega_0}=\ket{u_2}\bra{u_2}+\ket{u_3}\bra{u_3}=\begin{bmatrix}
      0&0&0\\0&1&0\\0&0&1
    \end{bmatrix}.
  \end{align*}
  The mean value is:
  \begin{align*}
    \braket{H}_\psi=\braket{\psi|H|\psi}=\sum_{n=1}^2\sum_{i=1}^{g_n}\braket{\psi|H|u_n^i}\braket{u_n^i|\psi}=\sum_{n=1}^2E_nP(E_n)=(\hbar\omega_0)\frac{1}{2}+(2\hbar\omega_0)\frac{1}{2}=\frac{3\hbar\omega_0}{2}.
  \end{align*}
  On the other hand, the term $\braket{H^2}_\psi$ is:
  \begin{align*}
    \braket{H^2}_\psi=\sum_{n=1}^2E_n^2P(E_n)=(\hbar\omega_0)^2\frac{1}{2}+(2\hbar\omega_0)^2\frac{1}{2}=\frac{5\hbar^2\omega_0^2}{2}.
  \end{align*}
  Then,
  \begin{align*}
    \Delta H=\sqrt{\braket{H^2}-\braket{H}^2}=\sqrt{\frac{5\hbar^2\omega_0^2}{2}-\left(\frac{3\hbar\omega_0}{2}\right)^2}=\frac{\hbar\omega_0}{2}.
  \end{align*}
  \item In order to define the probability of every outcome, we will define first the projector for every result:
  \begin{align*}
    P_a&=\ket{u_1}\bra{u_1}+\ket{+}\bra{+}=\ket{u_1}\bra{u_1}+\frac{1}{2}[\ket{u_2}\bra{u_2}+\ket{u_2}\bra{u_3}+\ket{u_3}\bra{u_2}+\ket{u_3}\bra{u_3}]=\frac{1}{2}\begin{bmatrix}
      2&0&0\\0&1&1\\0&1&1
    \end{bmatrix},\\
    P_{-a}&=\ket{-}\bra{-}=\frac{1}{2}[\ket{u_2}\bra{u_2}-\ket{u_2}\bra{u_3}-\ket{u_3}\bra{u_2}+\ket{u_3}\bra{u_3}]=\frac{1}{2}\begin{bmatrix}
      0&0&0\\0&1&-1\\0&-1&1
    \end{bmatrix}.
  \end{align*}
  Now, the outcomes along with their probabilities are:
  {\small
  \begin{align*}
    a,&\qquad\text{with}\quad P(a)=\braket{\psi|P_a|\psi}=|\braket{u_1|\psi}|^2+\frac{1}{2}\left[|\braket{u_2|\psi}|^2+|\braket{\psi|u_2}\braket{u_3|\psi}|^2+|\braket{\psi|u_3}\braket{u_2|\psi}|^2+|\braket{u_3|\psi}|^2\right]=1\\
    -a,&\qquad\text{with}\quad P(-a)=\braket{\psi|P_{-a}|\psi}=\frac{1}{2}\left[|\braket{u_2|\psi}|^2-|\braket{\psi|u_2}\braket{u_3|\psi}|^2-|\braket{\psi|u_3}\braket{u_2|\psi}|^2+|\braket{u_3|\psi}|^2\right]=0.
  \end{align*}}
  Given the above, The state vector immmediately after a measurement will be:
  \begin{align*}
    \ket{\psi}\stackrel{(a)}{\Longrightarrow}\frac{P_a\ket{\psi}}{\sqrt{\braket{\psi|P_a|\psi}}}=\frac{1}{\sqrt{2}}\ket{u_1}+\frac{1}{2}\ket{u_2}+\frac{1}{2}\ket{u_3}.
  \end{align*}
  Recall that each eigenvalue has its own projector. It is used to compute probabilities and states after measurements.
  \item The system is conservative as the Hamiltonian is time-independent. Therefore, the evolution of the state to an arbitrary time $t$ is:
  \begin{align*}
    \ket{\psi(t)}=\sum_{n=1}^2\sum_{i=1}^{g_n}c_{n}^ie^{-iE_nt/\hbar}\ket{u_n^i}=\frac{1}{\sqrt{2}}e^{-i\omega_0t}\ket{u_1}+\frac{1}{2}e^{-i2\omega_0t}\ket{u_2}+\frac{1}{2}e^{-i2\omega_ot}\ket{u_3}.
  \end{align*}
  \item First, the mean value of $A$ over time needs to explicitly state the eigenequation for $A$:
  \begin{align*}
    A\ket{u_1}=a\ket{u_1},\quad A\ket{u_2}=a\ket{u_3},\quad A\ket{u_3}=2\ket{u_2}.
  \end{align*}
  \begin{align*}
    \braket{A}(t)&=\braket{\psi|A|\psi}=\sum_{n=1}^2\sum_{i=1}^{g_n}=\sum_{n=1}^2\sum_{i=1}^{g_n}\braket{\psi|A|u_n^i}\braket{u_n^i|\psi}\\
    &=\braket{\psi|A|u_1}\braket{u_1|\psi}+\braket{\psi|A|u_2}\braket{u_2|\psi}+\braket{\psi|A|u_3}\braket{u_3|\psi}\\
    &=\braket{\psi|A|u_1}\frac{1}{\sqrt{2}}e^{-i\omega_0t}+\braket{\psi|A|u_2}\frac{1}{2}e^{-i2\omega_0t}+\braket{\psi|A|u_3}\frac{1}{2}e^{-i2\omega_0t}\\
    &=a\braket{\psi|u_1}\frac{1}{\sqrt{2}}e^{-i\omega_0t}+a\braket{\psi|u_3}\frac{1}{2}e^{-i2\omega_0t}+a\braket{\psi|u_2}\frac{1}{2}e^{-i2\omega_0t}\\
    &=a\left[\frac{1}{\sqrt{2}}e^{i\omega_0t}\right]\frac{1}{\sqrt{2}}e^{-i\omega_0t}+a\left[\frac{1}{2}e^{i2\omega_0t}\right]\frac{1}{2}e^{-i2\omega_0t}+a\left[\frac{1}{2}e^{-i2\omega_0t}\right]\frac{1}{2}e^{-i2\omega_0t}\\
    &=\frac{a}{2}+\frac{a}{4}+\frac{a}{4}\\
    \braket{A}(t)&=a.
  \end{align*}
  The matrix formalism can also be used:
  \begin{align*}
    \braket{B}(t)&=\braket{\psi|B|\psi}\\
    &=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\cdot\begin{bmatrix}
      0&b&0\\
      b&0&0\\
      0&0&b
    \end{bmatrix}\cdot\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{-i\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}
    \end{bmatrix}\\
    &=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\cdot\frac{b}{2}\begin{bmatrix}
      e^{-i2\omega_0t}\\
      \sqrt{2}e^{-i\omega_0t}\\
      e^{-i2\omega_0t}
    \end{bmatrix}\\
    &=\frac{b}{2}\left[\frac{\sqrt{2}}{2}e^{-i\omega_0t}+\frac{\sqrt{2}}{2}e^{i\omega_0t}+\frac{1}{2}\right]\\
    \braket{B}(t)&=\frac{b}{2}\left[\sqrt{2}\cos\omega_0t+\frac{1}{2}\right].
  \end{align*}
  The mean value of $A$ is time-independent, while for $B$ is not.
  \item The probability for $A$ are:
    \begin{align*}
    a:\qquad P(a)&=\braket{\psi|P_b|\psi}=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\frac{1}{2}\begin{bmatrix}
      2&0&0\\0&1&1\\0&1&1
    \end{bmatrix}\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{-i\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}
    \end{bmatrix}=1.\\
    -a:\qquad P(-a)&=\braket{\psi|P_{-a}|\psi}=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\frac{1}{2}\begin{bmatrix}
      0&0&0\\0&1&-1\\0&-1&1
    \end{bmatrix}\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}\\\frac{1}{2}e^{i2\omega_0t}\\\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}=0.
  \end{align*}
  For $B$, we have the following eigensubspace projectors:
  \begin{align*}
    P_{b}&=\ket{+}\bra{+}+\ket{u_3}\bra{u_3}=\frac{1}{2}[\ket{u_1}\bra{u_1}+\ket{u_1}\bra{u_2}+\ket{u_2}\bra{u_1}+\ket{u_2}\bra{u_2}]+\ket{u_3}\bra{u_3}=\frac{1}{2}\begin{bmatrix}
      1&1&0\\1&1&0\\0&0&2
    \end{bmatrix}\\
    P_{-b}&=\ket{-}\bra{-}=\frac{1}{2}[\ket{u_1}\bra{u_1}-\ket{u_1}\bra{u_2}-\ket{u_2}\bra{u_1}+\ket{u_2}\bra{u_2}]=\frac{1}{2}\begin{bmatrix}
      1&-1&0\\-1&1&0\\0&0&0
    \end{bmatrix}.
  \end{align*}
  The possibilities are:
  \begin{align*}
    b:\qquad P(b)&=\braket{\psi|P_b|\psi}\\&=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\frac{1}{2}\begin{bmatrix}
      1&1&0\\1&1&0\\0&0&2
    \end{bmatrix}\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{-i\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}
    \end{bmatrix}\\
    &=\frac{1}{2}\left[\frac{1}{\sqrt{2}}\cos\omega_0t+\frac{5}{4}\right],\\
    -b:\qquad P(-b)&=\braket{\psi|P_{-b}|\psi}\\
    &=\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{i\omega_0t}&\frac{1}{2}e^{i2\omega_0t}&\frac{1}{2}e^{i2\omega_0t}
    \end{bmatrix}\frac{1}{2}\begin{bmatrix}
      1&-1&0\\-1&1&0\\0&0&0
    \end{bmatrix}\begin{bmatrix}
      \frac{1}{\sqrt{2}}e^{-i\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}\\\frac{1}{2}e^{-i2\omega_0t}
    \end{bmatrix}\\
    &=\frac{1}{2}\left[\frac{3}{4}-\frac{1}{\sqrt{2}}\cos\omega_0t\right].
  \end{align*}

  
\end{enumerate}
%%
\section*{Problem V}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*.]
  \item A free particle has the following Hamiltonian
  \begin{align*}
    H=\frac{P^2}{2m}+0.
  \end{align*}
  We use Ehrnfest's theorem to establish that $\braket{X}$ is linear of time:
  \begin{align*}
    \frac{d}{dt}\braket{X}&=\frac{1}{i\hbar}\braket{[X,H]}+\braket{\frac{\partial X}{\partial t}}\\
    &=\frac{1}{i\hbar}\braket{\frac{i\hbar P}{m}}+0\\
    &=\frac{1}{m}\braket{P}.\\
  \end{align*}
  If we differentiate the term $\braket{P}$ and assuming the initial time as $t=0$:
  \begin{align*}
    \frac{d}{dt}\braket{P}=-\braket{\partial_xV(X)}=0\longrightarrow\braket{P}(t)=\text{cte}=\braket{P(0)}.
  \end{align*}
  Then,
  \begin{align*}
    \frac{d}{dt}\braket{X}=\frac{\braket{P(0)}}{m}\longrightarrow \braket{X}(t)=\frac{\braket{P(0)}}{m}t+\braket{X(0)}.
  \end{align*}
  \item Doing the same for $X^2$ we have:
  \begin{align*}
    \frac{d}{dt}\braket{X^2}=\frac{1}{i\hbar}\braket{[X^2,H]}+\braket{\frac{\partial X^2}{\partial t}}=\frac{1}{i\hbar}\frac{i\hbar}{m}\braket{\{X,P\}}+0=\frac{1}{m}\braket{XP+PX}.
  \end{align*}
  In addition, the mean value of the anticommutator of $X$ and $P$:
  {\small
  \begin{align*}
    \frac{d}{dt}\braket{XP+PX}&=\frac{1}{i\hbar}\braket{[XP+PX,H]}+\braket{\frac{\partial(XP+PX)}{\partial t}}\\
    &=\frac{1}{i\hbar}\braket{[XP+PX,\frac{P^2}{2m}]}+0\\
    &=\frac{1}{i\hbar}\braket{[XP,\frac{P^2}{2m}]+[PX,\frac{P^2}{2m}]}\\
    &=\frac{1}{i\hbar}\braket{X[P,\frac{P^2}{2m}]+[X,\frac{P^2}{2m}]P+P[X,\frac{P^2}{2m}]+[P,\frac{P^2}{2m}]X}\\
    &=\frac{1}{i\hbar}\braket{\left([X,\frac{P}{2m}]P+P[X,\frac{P}{2m}]\right)P+P\left([X,\frac{P}{2m}]P+P[X,\frac{P}{2m}]\right)}\\
    &=\frac{1}{i\hbar}\braket{\left(\frac{i\hbar P}{m}\right)P+P\left(\frac{i\hbar P}{m}\right)}\\
    &=\frac{1}{i\hbar}\frac{i2\hbar}{m}\braket{P^2}\\
    \frac{d}{dt}\braket{XP+PX}&=\frac{2}{m}\braket{P^2}.
  \end{align*}}
  The integral of $d(XP+PX)/dt$ is
  \begin{align*}
    \int\frac{d}{dt}\braket{XP+PX}\;dt&=\braket{XP+PX}_0+\frac{2}{m}\int\braket{P^2}\;dt=\braket{XP+PX}_0+\frac{2}{m}\braket{P^2}_0t.
  \end{align*}
  We can replace this in the $\braket{X^2}$ equation:
  \begin{align*}
    \frac{d}{dt}\braket{X^2}=\frac{1}{m}\braket{XP+PX}=\frac{1}{m}\left[\braket{XP+PX}_0+\frac{2}{m}\braket{P^2}_0t\right]
  \end{align*}
  Now, we integrate one last time
  \begin{align*}
    \braket{X^2}(t)=\braket{X^2}_0+\frac{1}{m}\braket{XP+PX}_0t+\frac{1}{m^2}\braket{P^2}_0t^2.
  \end{align*}
  Which is similar to the cinematic function in classical mechanics, but this corresponds to the dimension of $[L^2]$. In the derivation we have assumed that $\braket{P^2}=\braket{P^2}_0=\text{cte}$ as we have 
  proven that $\braket{P}=\braket{P(0)}$. Also, recall $X$ and $P$ are not time-dependent.
\end{enumerate}

%%
\section*{Optional}
\section*{Problem VI}
\subsection*{Part 1.}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=(\alph*)]
  \item Given that $F(\lambda)=a\lambda^2+c$ and $G(\lambda)=b\lambda$, with $a,c\in\mathbb{R}^+$ and $b\in\mathbb{R}$, we plot the three scenarios required with 
  specific values for $(a,b,c)$.
  \begin{figure}[h!]
    \centering
    \begin{subfigure}{.3\columnwidth}
      \centering
      \begin{circuitikz}
        \def\a{1}
        \def\c{0}
        \def\b{1}
        \draw[arrow](-3,0)--(3,0)node[below]{$\lambda$};
        \draw[arrow](0,-3)--(0,3)node[right]{$F(\lambda)/G(\lambda)$};
        \draw[very thick,NavyBlue,domain=-1.5:1.5,samples=100] plot(\x,{ \a*\x*\x+\c });
        \draw[very thick,OliveGreen,domain=-1.5:1.5,samples=100] plot(\x,{ \b*\x });
        \draw(1,-1)node[align=center]{$a=\a$\\$b=\b$\\$c=\c$\\$D=1$};
      \end{circuitikz}
      \caption{$F(\lambda)=G(\lambda),\;\lambda_1\neq\lambda_2$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.3\columnwidth}
      \centering
      \begin{circuitikz}
        \def\a{1}
        \def\c{0}
        \def\b{0}
        \draw[arrow](-3,0)--(3,0)node[below]{$\lambda$};
        \draw[arrow](0,-3)--(0,3)node[right]{$F(\lambda)/G(\lambda)$};
        \draw[very thick,NavyBlue,domain=-1.5:1.5,samples=100] plot(\x,{ \a*\x*\x+\c });
        \draw[very thick,OliveGreen,domain=-1.5:1.5,samples=100] plot(\x,{ \b*\x });
        \draw(1,-1)node[align=center]{$a=\a$\\$b=\b$\\$c=\c$\\$D=0$};
      \end{circuitikz}
      \caption{$F(\lambda)=G(\lambda),\;\lambda_1=\lambda_2$}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.3\columnwidth}
      \centering
      \begin{circuitikz}
        \def\a{1}
        \def\c{1}
        \def\b{1}
        \draw[arrow](-3,0)--(3,0)node[below]{$\lambda$};
        \draw[arrow](0,-3)--(0,3)node[right]{$F(\lambda)/G(\lambda)$};
        \draw[very thick,NavyBlue,domain=-1.5:1.5,samples=100] plot(\x,{ \a*\x*\x+\c });
        \draw[very thick,OliveGreen,domain=-1.5:1.5,samples=100] plot(\x,{ \b*\x });
        \draw(1,-1)node[align=center]{$a=\a$\\$b=\b$\\$c=\c$\\$D=-3$};
      \end{circuitikz}
      \caption{$F(\lambda)>G(\lambda),\;\forall\lambda$}
    \end{subfigure}
  \end{figure}
  \item We equation both expression and solver using the quadratic formula:
  \begin{align*}
    a\lambda^2+c&=b\lambda\\
    a\lambda^2-b\lambda+c&=0
  \end{align*}
  The roots are:
  \begin{align*}
    \lambda_{1,2}=\frac{b\pm\sqrt{b^2-4ac}}{2a}=\frac{b\pm\sqrt{D}}{2a}.
  \end{align*}
  In order to have two real and distinct roots, we must have $D=b^2-4ac>0$.
  \item In this case, we have that 
  \begin{align*}
    a\lambda^2-b\lambda+c\geq0.
  \end{align*}
  The roots are same same that the previous cases:
  \begin{align*}
    \lambda_{1,2}=\frac{b\pm\sqrt{D}}{2a}\in\{\frac{b-\sqrt{D}}{2a},\frac{b+\sqrt{D}}{2a}\}.
  \end{align*}
  In this case, in order to satisfy that $F(\lambda)\geq G(\lambda),\;\forall\lambda$, we would have complex roots which can only happen for $D=b^2-4ac\leq0$.
\end{enumerate}
\subsection*{Part 2.}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=\alph*)]
  \item We can show it by using properties of Hermitian operation:
  \begin{align*}
      G^\dagger=(iF)^\dagger=-iF^\dagger=-iF=-G\Longrightarrow G^\dagger=-G.
  \end{align*}
  \item It can be prooved by looking the eigenvalues of the operator:
  \begin{align*}
    G\ket{\psi}=g\ket{\psi}\qquad\text{and}\quad(G\ket{\psi})^\dagger&=(g\ket{\psi})^\dagger\\
    \bra{\psi}G^\dagger&=g^*\bra{\psi}\\
    -\bra{\psi}G&=g^*\bra{\psi}\\
    \bra{\psi}G&=-g^*\bra{\psi}.
  \end{align*}
  Therefore, if under an adjoint operator the eigenvalue changes from $g$ to $-g^*$, it means that it is a pure imaginary term. If it would have consisted of also a real part,
  it will not be possible to extract the minus sign from $g$. The same can be done for the expectation value:
  \begin{align*}
    \braket{\psi|G|\psi}^\dagger=\braket{\psi|G^\dagger|\psi}=-\braket{\psi|G|\psi}.
  \end{align*}
  The minus sign reveals the same nature on this number.
  \item The commutator already has a property for the adjoint, we will use it and also the inversion of the arguments with the minus sign included:
  \begin{align*}
    ([A,B])^\dagger=[B^\dagger,A^\dagger]=-[A^\dagger,B^\dagger]=-([A,B])^\dagger.
  \end{align*}
  The other follows the same idea:
  \begin{align*}
    \braket{\psi|[A,B]|\psi}^\dagger=\braket{\psi|[A,B]^\dagger|\psi}=-\braket{\psi|[A,B]|\psi}.
  \end{align*}
  We have used the previous results of the commutator directly.
\end{enumerate}


\subsection*{Part 3}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=(\alph*)]
  \item The scalar product is:
  \begin{align*}
    \braket{\phi|\phi}&=\bra{\psi}(A-i\lambda B)(A+i\lambda B)\ket{\psi}\\
    &=\braket{\psi|A^2|\psi}+\braket{\psi|i\lambda AB-i\lambda BA|\psi}+\braket{\psi|\lambda^2B|\psi}\\
    &=\braket{\psi|A^2|\psi}+i\lambda\braket{\psi|[A,B]|\psi}+\braket{\psi|\lambda^2B^2|\psi}\\
    \braket{\phi|\phi}&=\braket{A^2}+i\braket{[A,B]}\lambda+\braket{B^2}\lambda^2\geq0.
  \end{align*}
  This consists of a second-order polynomial of $\lambda$.
  The roots must be complex, which implies that the determinant must be $D\leq0$:
  \begin{align*}
    D=\braket{[A,B]}^2-4\braket{B^2}\braket{A^2}\leq0\longrightarrow\braket{A^2}\braket{B^2}\geq\frac{1}{4}|\braket{[A,B]}|^2.
  \end{align*}
  \item To verifty that $[A',B']=[A,B]$ we substitute $A'=A-\braket{A}$ and $B'=B-\braket{B}$:
  \begin{align*}
    [A',B']&=A'B'-B'A'\\
    &=(A-\braket{A})(B-\braket{B})(B-\braket{B})(A-\braket{A})\\
    &=AB-A\braket{B}-\braket{A}B+\braket{A}\braket{B}-BA+B\braket{A}+\braket{B}A-\braket{B}\braket{A}\\
    &=AB-BA\\
    [A',B']&=[A,B].
  \end{align*}
  This implies that we could began with $A'$ and $B'$ in the second-order equation. Therefore, it is a matter or substitue $A$ by $A'$ and $B$ by $B'$:
  \begin{align*}
    \braket{(A')^2}\braket{(B')^2}\geq\frac{1}{2}|\braket{[A,B]}|^2.
  \end{align*}
  \item This derivation is strongly linked with the above one. 
  \begin{align*}
    \braket{(A')^2}\braket{(B')^2}&\geq\frac{1}{4}|\braket{[A,B]}|^2\\
    \braket{(A-\braket{A})^2}\braket{(B-\braket{B})^2}&\geq\\
    \braket{(A^2-2A\braket{A}+\braket{A}^2)}\braket{(B^2-2B\braket{B}+\braket{B}^2)}&\geq\\
    \left(\braket{A^2}-2\braket{A}^2+\braket{A}^2\right)\left(\braket{B^2}-2\braket{B}^2+\braket{B}^2\right)&\geq\\
    \left(\braket{A^2}-\braket{A}^2\right)\left(\braket{B^2}-\braket{B}^2\right)&\geq\\
    (\Delta A)^2(\Delta B)^2&\geq\frac{1}{4}|\braket{[A,B]}|^2.
  \end{align*}
  \item If two observables $Q$ and $P$ have the commutation $[Q,P]=i\hbar$, we can compare them with the initial statement that 
  \begin{align*}
    \ket{\phi}=(A+i\lambda B)\ket{\psi}\quad\text{with}\quad [A,B]=iC.
  \end{align*}
  Then, $C=\hbar$ for this case. Also, by doing the derivation we could also get the relation in terms of $Q$ and $P$. Is now just a matter of replace them:
  uncertainty:  
  \begin{align*}
    (\Delta Q)^2(\Delta P)^2\geq\frac{1}{4}|\braket{[Q,P]}|^2=\frac{1}{4}|\braket{i\hbar}|^2=\frac{1}{4}|i\hbar|^2=\frac{\hbar^2}{4}.
  \end{align*}
\end{enumerate}


\section*{Problem VII}
\begin{enumerate}[itemsep=0pt,topsep=0pt,label=(\alph*)]
  \item Im sure this is not the best way, but basically I took out the integration operator and the integrand is left is $[H(t),H(t')]$ which is non-zero by 
  assumption. Therefore, if we assume the integrand to be monotonically positive, there is no form to get zero:
  \begin{align*}
    [H(t),H(t')]\neq0\Longrightarrow \int_{t_0}^t[H(t),H(t')]\;dt'\neq0.
  \end{align*}
  The only way it can be zero if the commutator is negative and also positive so that may exist a completely cancellation.
  \item We will assume that $H(t_0)$ is a constant and therefore can commute:
  \begin{align*}
    \left[F(t),\frac{d}{dt}F(t)\right]&=-\frac{1}{\hbar^2}\left[\int_{t_0}^tH(t')\;dt',\int_{t_0}^t\frac{d}{dt}H(t'')\;dt''\right]\\
    &=-\frac{1}{\hbar^2}\left[\int_{t_0}^tH(t')\;dt',H(t)-H(t_0)\right]\\
    &=-\frac{1}{\hbar^2}\left[\int_{t_0}^tH(t')\;dt',H(t)\right]-\frac{1}{\hbar^2}\left[\int_{t_0}^tH(t')\;dt',H(t_0)\right]\\
    \left[F(t),\frac{d}{dt}F(t)\right]&=-\frac{1}{\hbar^2}\left[\int_{t_0}^tH(t')\;dt',H(t)\right].
  \end{align*}
  The other equation can be easily verified by using the $[A,B]=-[B,A]$ identity.
  \item I couldnt :( 
  \item We use separation of variable by thinking of $y=U(t,t_0)$:
  \begin{align*}
    \frac{dU(t,t_0)}{dt}\frac{1}{U(t,t_0)}&=-\frac{i}{\hbar}H(t)\;\biggr/\int_{t_0}^t\;dt\\
    \ln U(t,t_0)&=-\frac{i}{\hbar}\int_{t_0}^tH(t')\;dt'\bigr/e^t\\
    U(t,t_0)&=e^{-\frac{i}{\hbar}\int_{t_0}^tH(t')\;dt'}.
  \end{align*}
  I dont know how $[H(t),H(t')]=0$ restricts the above.
\end{enumerate}

%\nocite{*}
%\bibliographystyle{plain}   % or unsrt, alpha, apalike, etc.
%\bibliography{refs}

\end{document}
